{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the right metric for evaluating Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall or Sensitivity or TPR(True Positive Rate):**\n",
    "Number of items correctly identified as positive out of total true positive -TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity or TNR(True Negative Rate):** Number of item correctly identified as negative out of total negatives-TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision: ** Number of item correctly identified as positive out of total items identified as positive -TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate or Type I Error:** Number of items wrong identified as positive out of total true negatives- FP(FP/TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Negative Rate or Type II Error:** Number of items wrongly identified as negative out of total true postive-FN/(FN+TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score:** It is a harmonic mean of precision and recall given by $F1 = 2*Precision*Recall/(Precision + Recall)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** Percentage of total items classified correctly-\n",
    "(TP+TN)/(N+P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-AUC Score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receiver operating characteristic- Area under curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, it is calcualted by area under of sensitivity(TPR) vs FPR(1-specificity). Ideally, we would like to have high sensitivity & high specificity, but in real-world scenarios, there is always a tradeoff between sensitivity & specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important characteristics of ROC-AUC are:\n",
    "\n",
    "    * The value can range from 0 to 1. However auc score of a random classifier for balanced data is 0.5\n",
    "    \n",
    "    * ROC-AUC score is independent of the threshold set for classification because it only considers the rank of each prediction and not its absolute value. The same is not true for F1 score which needs a threshold value in case of probabilities output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-loss is a measurement of accuracy that incorporate the idea of probabilistic confidence given by following expression for binary class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-(y log(p)) + (1-y)log(1-p))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes into account the uncertainty of your prediction based on how much it varies from the actual label. In teh worst case, let's say you predicted 0.5 for all the observations. So log-loss will become -log(0.5) = 0.69. Hence, we can say that anything above 0.6 is a very poor model considering the actual probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
